{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a9a5fd-4895-464f-899c-6708ca3a87c9",
   "metadata": {},
   "source": [
    "Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n",
    "Ans-> In OLS regression, the goal is to minimize the sum of the squared differences between the observed responses (yy) and the responses predicted by the linear model (y^). The objective function is:\n",
    "\n",
    "OLS Objective:min⁡β∑i=1n(yi−y^i)2OLS Objective:minβ*∑i=1/n(yi−y^i)2\n",
    "Differences Between Ridge Regression and OLS Regression\n",
    "\n",
    "    Regularization:\n",
    "        OLS Regression: Does not include any regularization. The objective is to minimize the sum of squared errors.\n",
    "        Ridge Regression: Includes an L2 regularization term (λ∑j=1pβj2λ∑j=1p​βj2​) in the objective function to prevent overfitting and reduce the variance of the model.\n",
    "\n",
    "    Handling Multicollinearity:\n",
    "        OLS Regression: Sensitive to multicollinearity among predictors, leading to high variance in coefficient estimates.\n",
    "        Ridge Regression: Mitigates multicollinearity by shrinking the coefficients, which can stabilize the estimates.\n",
    "\n",
    "    Coefficient Estimates:\n",
    "        OLS Regression: Can produce large coefficients if the predictors are highly correlated, leading to overfitting.\n",
    "        Ridge Regression: Shrinks the coefficients towards zero but does not set any of them exactly to zero, reducing overfitting.\n",
    "        Interpretability:\n",
    "\n",
    "    OLS Regression: The coefficients represent the exact effect of each predictor on the response variable.\n",
    "    Ridge Regression: The coefficients are shrunk, which can make interpretation less straightforward, but the model is more stable and generalizes better to new data\n",
    "    \n",
    "    \n",
    "\n",
    "Q2. What are the assumptions of Ridge Regression?\n",
    "Ans-> Assumptions of Ridge Regression\n",
    "\n",
    "    Linearity:\n",
    "        The relationship between the independent variables (predictors) and the dependent variable (response) is linear. This means that the change in the response variable is proportional to the change in the predictor variables.\n",
    "\n",
    "    Independence:\n",
    "        The observations are independent of each other. This means there is no correlation between the residuals (errors) of different observations.\n",
    "\n",
    "    Homoscedasticity:\n",
    "        The variance of the error terms (residuals) is constant across all levels of the independent variables. In other words, the spread of the residuals should be roughly the same for all predicted values.\n",
    "\n",
    "    Normality of Errors:\n",
    "        The error terms are normally distributed. This assumption is particularly important for hypothesis testing and constructing confidence intervals.\n",
    "\n",
    "    No Perfect Multicollinearity:\n",
    "        While Ridge Regression can handle multicollinearity better than OLS by shrinking the coefficients, it assumes that there is no perfect multicollinearity (i.e., no perfect linear relationship among the predictors). In cases of perfect multicollinearity, Ridge Regression cannot uniquely estimate the coefficients.\n",
    "\n",
    "    Fixed Independent Variables:\n",
    "        The values of the independent variables are fixed in repeated samples. This means the predictors are measured without error.\n",
    "        \n",
    "        \n",
    "        \n",
    "Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n",
    "Ans->\n",
    "Q4. Can Ridge Regression be used for feature selection? If yes, how?\n",
    "Q5. How does the Ridge Regression model perform in the presence of multicollinearity?\n",
    "Q6. Can Ridge Regression handle both categorical and continuous independent variables?\n",
    "Q7. How do you interpret the coefficients of Ridge Regression?\n",
    "Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
